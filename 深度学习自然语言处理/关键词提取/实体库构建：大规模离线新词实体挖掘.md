实体库构建：离线新词发现流程

命名体识别我们一般有两个操作：词典匹配+模型预测。

对于词典匹配来说，速度快，准确度高。但是有一个问题是由于不同人对同一个东西有不同的表达，所以OOV问题比较严重。

缓解OOV，我们可以使用模型预测增加泛化，还可以离线挖掘实体进行补充实体库。

美团在这个文章中提到了一种新词离线挖掘补充实体库的方法，我借鉴了其中的思路，并且用到了自己工作中，效果还不错。在这个文章，我主要是详细解读一下整个过程。

我们聊一下为什么需要做新词发现？

新词是什么？按照最普通的定义就是我词典中不存在的词汇都属于新词。如果按照这个思路去挖掘新词，我们一般使用两种方法：有监督和无监督。

无监督一般来说就是使用紧密度加自由度调整阈值就可以提取新词。但是这种方法有一个问题，就是你这个阈值的调整到哪里才可以，这个取决于你的召回和精确的一个平衡。

有监督的话，一个简单的思路就是序列标注做中文分词，出来的词汇不在字典中的我们就可以作为新词。

但是我们想一下这样新词出现的是什么情况？

举个最简单的例子，可能你挖掘出来的就是“爷青结”这样的词汇，确实是新词，不在我们已经有词典中，但是对于我们的实体库有没有帮助呢？

有没有帮助要看我们的目的。如果说我们的目的是为了分词的准确，那么这个新词完全可以用，直接放到txt文件中，保证下回分类的准确。

但是在这里，我们是做的事情是为了补充实体库，也就是需要有意义的词汇，比如说“外滩十八号”这种词汇。

所以，普通的新词发现的有监督和无监督方法只能挖掘词汇，不能保证挖掘的是实体。

基于此目的，可以借鉴新词挖掘的思路，对词汇做二元分类判断是不是实体的有监督方法就很容易想到。

总结下来步骤就是这样：

1. 挖掘频繁项

2. 提取频繁项的各种统计特征

3. 频繁项和已经有的实体交集作为正样本，负采样得到负样本。使用多个分类器进行集成，训练多个二元分类器。

采用负样本的时候，美团有提到一个论文，大家可以去看一下。

4. 搜索日志中搜索次数比较高的词条和正样本的交集作为高质量短语，负样本减去词条作为低质量短语，使用Bert训练质量打分器。

整个流程通读下来，其实很好理解。

一般来讲，如果实践过程，第四个步骤其实很难做。

我是这样想的，首先这个美团搜索很垂直，一般搜索属于短query，你很难去在美团搜索框去搜一个很长的句子。

这种情况下，就会出顾客的搜索记录本身就是高质量的短语或者实体。想一下是不是这样，你去搜“来杯啤酒烧烤”，这本身就是个商户名称，就是个实体。所以交集才可以作为高质量短语。

如果你是个大搜的搜索日志，这种情况基本不存在的，有长短语，有短的词汇，你找交集的阈值都无从下手。

第二个难点就是Bert打分器这个东西的可靠性。一般来说实体的字数都比较少，比如五六个字，字数这么少，这个打分究竟可靠不可靠我没有实践过，只是有这个疑惑。

整个做完，还有一个问题，实体库是分类别的，比如美食有一个词典，景点有一个词典等等吧。我们上面挖掘出来的是全部的实体，不分类别的，那么怎么分类呢？

美团提到他们使用的AutoNER，大家可以去看一下相关论文。针对这一块，其实能做的思路还挺多的，由于工作原因，这块我就不说了。大家可以发散思路。