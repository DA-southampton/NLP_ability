今天主要聊我在做多模态任务中的六个方面的介绍，如下：

1. 多模态业务简单介绍；
2. 多模态数据问题；
3. 如何确保多模态任务的预测速度；
4. 如何确定多模态任务确实起到了作用；
5. 多模态中多张图片如何处理；
6. 交互的时候哪种attention方式更好；
7. 训练的时候需要注意什么；

**1.多模态业务简单介绍；**

之前花了不少时间在多模态这块的落地工作，取得了一定的效果，今天分享一下我的经验；

首先在调研多模态任务的时候大家可以看一下最近的论文，这两年的多模态任务基本上都在往Transformer上去靠，基本可以分为两种：单流网络和双流网络；

双流网络就是文本过一个编码器，图片过一个编码器，然后两个编码器的输出进行一个交互；

单流网络就是文本和图片先concat，然后直接输入到Transformer编码器中，然后输出；

一般来说，这里的编码器使用的都是TRM结构；

文本这块，输出的时候得到的是embedding就可以；图片这里，一般来说使用的是Faster-RCNN模型识别出图片中包含的多个物体及其对应的矩形位置信息，把这个作为TRM的输入；

但是我在真正去做的时候，并没有按照这个思路去做，我是先按照自己的思路做了个baseline，然后有效果，之后再去看论文架构提升模型效果；

我简单分享一下我的主体思路，文本过的BERT，图像过的Resnet,然后输出的两个表征向量之间做多头注意力，然后接全连接输出logits；

按照分类，我这个架构应该属于双流网络；

架构其实很简单，但是在真正去做的时候，真的是比较复杂，有很多细节，我在这里简单的梳理一下，一起探讨；

**2.多模态数据问题；**

多模态一般来说就是双模态数据，我主要接触的是文本+图片；很幸运，我有标注数据~~ 如果没有基于自己场景下的标注数据，还是不太建议强行上多模态任务；

**3.如何确保多模态任务的预测速度；**

为了保证我的预测速度，我不可能所有的case都过多模态网络；所以我做的策略很简答，就是单从文本输出结果置信度不高的而且含有图片信息的case走多模态任务；

**4.如何确定多模态任务确实起到了作用；**

这个问题其实很关键，首先我们当然可以做测试集，验证一下单走文本或者单走图片得到的f1以及做多模态得到的f1，两者一个比较就可以；

当时确实也这么做了，但是我纠结点在于能不能使用一种可见的方式，告诉大家多模态度确实起到了作用？

那么一个很有用的方法就是使用attention的可视化；这个方法可以可视化出文本和图片之间确实是有交互的，而且交互的部分是有意义的，比如有的单词就是对图片中的某个部分更加关注；

**5.多张图片如何处理；**

因为我图片过的是Resnet网络，所以输入是多张图片的数量是动态的，这是个问题；

我们退一步说，按照现在bert多模态预训练中的方法，多张图片完全可以作为transformer中的输入tokens部分；或者把多张图片合并在一起生成一个图片再走正常流程；

我这边处理的时候需要注意的细节就是resnet输出池化的时候k是个动态的池化就可以；

**6.哪种attention方式更好；**

一般来说做互相之间的交互更好，就是文本对图片做一次attention，图片对文本做一次attention，两者结合来做；

**7.训练的时候需要注意什么；**

bert和resnet网络架构不太一样，训练的时候容易不收敛，需要控制一下不同部分的学习率；

如上，因为业务的原因，很多东西不能细说，所以我只是大体的介绍了一些自己的经验，希望能对大家有帮助；

之后我会写一些BERT多模态预训练论文的解读文章，大体是**LXMERT，ViLBERT，Unicoder-VL、VisualBERT、VL-VERT、UNITER**等等；

**求点赞，求在看，求转发，求一切，爱你们哦~ ~**