今天分享一个论文，[UDA](https://arxiv.org/abs/1904.12848 "Unsupervised Data Augmentation for Consistency Training")，效果惊人：通过UDA，在IMDb文本分类数据集上，使用20个标签数据，相当于使用25000个标签数据。

先说一个概念，贯穿在整个论文：consistency training

直译过来就是一致性训练，我自己的理解就是，对于无标注数据，加入噪声，标签不变（或者说数据代表的含义没有发生太大的变化）

UDA这个论文就是做了一个事情，验证监督学习中的数据增强方式放在半监督中作为一种噪声输入是有效的，是可以提升模型表现能力的。

# 1. UDA

先说有监督情况下的数据增强

数据增强的目的是通过对示例进行转换而无需更改其标签，从而扩充数据。

然后说一下半监督学习本质上在解决一个什么问题？

我的数据中，有标注数据和无标注数据，半监督学习本质上是在从无标注数据上学下一个信息和知识从而使得模型效果更好，更佳的平滑和健壮。

一般的半监督模式是这样的：

1. 输入数据为$x$，分别计算两个东西，原本的输出分布：$p_{\theta}(y|x))$，输入数据注入噪声之后的输出分布：$p_{\theta}(y|x,\varepsilon)$。
2. 最小化两个差异之间的度量:$D(p_{\theta}(y|x)) || p_{\theta}(y|x,\varepsilon))$

此过程使模型对噪声不敏感，因此相对于输入（或隐藏）空间的变化更平滑。从另一个角度看，将一致性损失降至最低会逐渐将标签信息从已标记的示例传播到未标记的示例。

这句话我是这理解的，输入空间越平滑，输入向量发生细微的变化，也就是加入扰动或者说噪声之后，代表的含义没咋变，标签就没咋变。

之前的一些工作，为了达到上述这点，也就是为了增强一致性，通常采用简单的噪声注入方法，例如将高斯噪声，简单的输入增强添加到未标记噪声的示例中。

与之相反，这里使用的是将监督学习中的数据增强的方法在这里作为噪声加入到原始数据中。

在监督学习中，数据增强的做法的一个前提是，增强之后，标签不变。

半监督中，我们加入噪声的目的是为了，加入噪声之后，原始数据的输出和加入噪声之后的输入向量的度量差异越小越好，越接近越好。

这两个其实可以很类似，这也是我觉得谷歌在这个论文 中探讨的一点，就是监督学习中的数据增强可不可以作为一种半监督中的噪声扰动。

先来看**损失函数**：

![一致性训练损失函数](https://picsfordablog.oss-cn-beijing.aliyuncs.com/2020-12-01-090750.jpg)

重点是后半部分，是在无标签数据上的一致性损失函数。需要注意，后半部分的参数是固定的，从前部分模型直接复制过来的，简单来说就是不参与训练。

整体架构如下：

![UDA架构图](https://picsfordablog.oss-cn-beijing.aliyuncs.com/2020-12-01-090749.jpg)

# 2. 训练技巧

## 2.1 数据增强

我以NLP中的任务为例：

1. 回译
2. 注意些主题分类任务的时候，有些单词很重要，通过TF-IDF来保留这些单词。

这里其实很想说一下这个TF-IDF替换词这个东西，在附录里找到，好好的翻看了一下。

概括一样是做了两个步骤（不知道我有没有理解准确）：

1. 对于句子中的每个单词计算替换概率
2. 替换的时候是从语料中抽取单词（简单粗暴），所以还计算了一个语料中每个单词的是不是关键词的概率。如果是关键词，那么就不能要，因为如果替换到当前的句子，可能让当前句子的类别发生改变。

具体的计算公式，大家可以去看一下原论文。

## 2.2 Confidence-based masking

我们发现掩盖当前模型不确定的示例会有所帮助。具体而言，在每个小批量中，仅对分类类别中最高概率大于阈值β的示例计算一致性损失项。将阈值β设定为较高的值。

简单来说，一致性损失应该针对的是无标签的数据，我们在训练的时候，只是计算那些输出概率高于阈值的样本，其余样本直接抛弃掉。

## 2.3 Sharpening Predictions

如果训练的时候使用了Confidence-based masking，我们可以结合Sharpening Predictions来提升模型的表现。

什么是Sharpening Predictions？就是通过设定温度参数，改变最后softmax的分布，使它更加的尖锐，也就是熵更小，分布的越集中。

这个东西蒸馏的时候也有用到，只不过在蒸馏的时候我们需要的是扩大不同类别的相似性，温度参数是大于1比较好的。但是这里我们希望是集中输出的分布，让它的熵更小，所以温度参数应该小于1。

从另一个角度来说，使用了温度参数之后，阈值大于0.8 的概率应该也会提升，这就让Confidence-based masking变得没有那么难以操作。

## 2.4 Domain-relevance Data Filtering

首先我们要明白的是我们的数据中是含有无标签数据的，那么基于此，我们很容易有这么一个想法：

既然有无标签数据了，那么为了增大模型的表达能力，能不能我自己从别的地方收集更多无标签数据补充进来，仍然使用同样的流程，这样最终模型效果是不是更好。

这个想法很朴素，有一个问题就是我们从外部收集的数据是不是和我们已经有的数据同分布的。

举个简单的例子，如果我们当前的数据的10个类别分类的数据，你从外部收集的数据类别是超出这个10个类别的，那么这样的数据加入进来，是副作用。

一个很简单的方法就是，我们使用在域内数据上训练的基线模型来推断大型域外数据集中的数据标签，并选择模型最有信心的示例。具体而言，对于每个类别，我们根据分类属于该类别的概率，并选择概率最高的示例。

这其实本质上也是无监督的一种方式，具体看一下这个文章。

## 2.5 TSA 

全称是Training Signal Annealing for Low-data Regime，直译过来是低数据状态的训练信号退火；

为什么使用这个东西？它本质上是为了解决一个问题就是无标签数据和有标签数据的数量巨大的不平衡问题。

也就是说标签数据少，无标签数据多，在训练的时候很容易在标签数据上造成过拟合。

TSA基本思想就是我们首先定义一个阈值，在训练的时候，我们只是使用模型对于当前标注数据的输出置信度低于阈值的样本。

比如说，阈值如果你定的是0.5，那么在训练的时候，标注数据的输入最大概率如果是0.9，那么这个样本的是不计算在损失内，如果是0.1，那么我们计算损失。

这个阈值是随着训练不停的增加的，有三种方式，如图：

![TSA](https://picsfordablog.oss-cn-beijing.aliyuncs.com/2020-12-01-090751.jpg)

如果说标注数据很容易学习，或者说标注数据很少，我们使用指数增加。

因为标注数据少或者容易学习，刚开始很容易过拟合，置信度高的样本占比多，所以我么最开始增长的慢。

相反，当模型不太可能过拟合时，例如，当我们有大量带标签的示例或模型采用有效的正则化时，对数计划可以很好地发挥作用。

总的来说，TSA本质上给人的直观感觉更像是在训练初期，压迫模型，不要尽快的学到最好的表现能力（使劲的扯后腿。。。）

# 3. 实验结果

![UDA实验结果](https://picsfordablog.oss-cn-beijing.aliyuncs.com/2020-12-01-090748.jpg)

有效，不想多分析

# 4. 总结

说一下从这个论文学到的东西。

1. 数据增强在半监督中可以作为噪声输入提升模型表现，文中使用的回译和TF-IDF。其实NLP中监督学习中有效的数据增强方法很多，猜测其他方法也是有效的，可以去尝试。
2. 上一个文章提到，为了担心模型在无标签数据上表现不好，在最开始，只是使用的标签数据，然后无标签数据才慢慢加进来的。当时使用的是一个$\alpha(t)$来控制。在这里，为了缓解这个问题，使用的是masking结合Sharpening，Sharpening来控制输出的熵，让它比较尖锐，masking让它舍弃低置信度的样本，防止误差累积。
3. 第2点注意是针对的一致性损失，也就是无标签数据做的这个操作，对于有标签数据，我们使用TSA，来缓解过拟合，核心思想就是抛弃掉置信度高的样本，压迫模型在初期不要表现的那么好。

半监督这块，我只是在工作中简单涉及到了，所以没有深入的读大量的论文，只是针对我用到的一些东西，看了一些论文。

文中有不对的内容，欢迎大家拍砖讨论。

参考资料：

谷歌惊艳的无监督数据增强方法--Unsupervised Data Augmentation for Consistency Training

https://www.jianshu.com/p/5d4e18b8de04

半监督学习在金融文本分类上的探索和实践 - 李渔的文章 - 知乎 https://zhuanlan.zhihu.com/p/151021586

Google无监督数据增强方法UDA在文本分类上的实验 - 延陵既智的文章 - 知乎 https://zhuanlan.zhihu.com/p/186211797