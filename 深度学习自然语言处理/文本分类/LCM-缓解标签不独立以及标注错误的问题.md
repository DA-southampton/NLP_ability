今天分享一个论文[LCM](https://arxiv.org/pdf/2012.04987.pdf, "Label Confusion Learning to Enhance Text Classification Models")；这个论文掌握以下几点，使用LCM模型：

1. 可以捕捉标签与标签之间的关系
2. 可以捕捉标签和样本之间的关系
3. 在噪声数据集，效果比LS要好

# 1. 文本分类普遍存在一个问题

深度学习模型进行文本分类有一个共性：

1. 首先使用一个比较深的模型去做text representation；

2. 然后使用一个简单的分类层（比如全连接）去预测标签分布；

3. 之后计算预测标签分布和真实one-hot标签向量的交叉熵。

这个流程其实是有问题的；

从标注规则来看，使用one-hot的前提是假设你的数据集中的标签是相互独立的。

但是这种假设在现实中基本不会有，只是或多或少，有的界限比较清晰，有的不清晰的问题而已；

还有一个问题从样本来看，如果是单标签分类，同一个样本真实情况下可能对应多个类别。

比如【今天去公园野炊一下，吃点烧烤呗】；类别可能是【美食】，也可能是【旅游】，也可能是其他的类别。

这个可能并不明显，我举个最明显的例子：【郭麒麟相声说的是真棒啊，综艺是真好看啊，综艺感真实爆棚了】；

上面这个例子，你说它的类别是【相声】？【综艺】？【娱乐明星】？

还有一个问题，就是标注错误的问题。这种情况一般使用标签平滑。

标签平滑让真实标签不那么极端化，给与标签一定的容错概率。

但是标签平滑本质上加了一个噪声，并不是真实反映标签的分布情况。

从这出发，就可以看出下面LCM主要去解决以下问题：

1. 标签之间并不相互独立，所以我们需要一种方式能够度量标签之间的关系

2. 样本可能对应多个标签，所以我们需要一种方式能够度量样本和每个标签之间的关系

3. 标签可能标注错误，所以我们尽量不适用one-hot硬标签，而是使用软化之后的标签。



# 2. LCM-架构图

先来看架构图

![LCM架构图](https://picsfordablog.oss-cn-beijing.aliyuncs.com/2020-12-10-105718.jpg)

架构图最核心的部分注意看紫色的Similarity Layer层，这一层主要做的是对经过深度学习模型学到的句子表达和label的表达进行相似性度量。

然后把这个相似性的度量加到one-hot标签中。

看一下公式就明白了，左半部分比较简单，就不说了，看右半部分：

![SLD](https://picsfordablog.oss-cn-beijing.aliyuncs.com/2020-12-10-105717.jpg)

$f^{L}$是对labels进行encode，得到每个label的表达向量，方便和句子向量做 dot product。

注意图中的参数$\alpha$，代表了相似性这个信息对原始标签的影响。

损失函数使用的是KL散度

# 3. 实验结果

方法有效，就不放实验图了。

我比较感兴趣的是 label embedding究竟有没有学到相似性，看图：

![label representations](https://picsfordablog.oss-cn-beijing.aliyuncs.com/2020-12-10-105719.jpg)

不同颜色代表将类别根据语义分为不同的组，可以看到同个颜色的labels很大情况下还是挨得很近的。

说明架构图有半部分的下半部分，也就是那个label encoder确实是有作用的。

还比较感兴趣的是LCM和标签平滑的对比，看图确实比LS更好一点：

![LCM with LS](https://picsfordablog.oss-cn-beijing.aliyuncs.com/2020-12-10-105715.jpg)

# 总结

简单总结一下，

1. LCM挖掘了标签之间的关系和标签与样本之间的关系
2. 样本数据如果噪声标签（标注错误），LCM有效
3. 样本数据的标签如果界限比较模糊（根据语义可以划分为多个组），LCM有效

整个论文最核心的点，我认为是对lables做了编码，从而有机会去和句子编码进行交互，度量相似性。并将整个相似性信息加入到了原始标签中。

所以网络在训练的时候，学习到的信息更加的丰富。